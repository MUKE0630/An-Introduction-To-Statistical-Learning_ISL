# Statistical Learning

# 什么是统计学习

建立 $X$ 与 $Y$ 的关系，通常可以写为：$Y=f(X)+\epsilon$ 其中 **$\epsilon$ 是独立于  $X$ 均值为0的随机误差项**。我们通过数据，确定 $f$ 

### 为什么评估 $f$

估计函数 $f$ 可用于预测和推断

- 预测
    
    假设 $\hat{f}$ 和 $X$ 都是确定的，那么唯一的变量来自于 $\epsilon$ 
    
    $$
     \begin{aligned}\mathrm{E}(Y-\hat{Y})^{2} & =\mathrm{E}[f(X)+\epsilon-\hat{f}(X)]^{2} \\& =\underbrace{[f(X)-\hat{f}(X)]^{2}}_{\text {Reducible }}+\underbrace{\operatorname{Var}(\epsilon)}_{\text {Irreducible }}\end{aligned}\tag{2.3}
    $$
    
    其中 $Var(\epsilon)$ 表示与误差项 $\epsilon$ 相关的方差
    

### 如何估计 $f$

- 参数法 *parametric methods*
    1. 对 $f$  的形式进行假设（例如假设为线性回归 $f(X)=\beta_{0}+\beta_{1} X_{1}+\beta_{2} X_{2}+\cdots+\beta_{p} X_{p}$ ）
    2. 使用训练数据进行模型拟合
    
    线性回归模型一般使用最小二乘法来拟合，
    
    参数法的潜在缺点是，我们选择的模型与 $f$ 的真实形式不匹配，可以通过选择灵活的模型来解决这个问题，但越复杂越灵活的模型会引起过拟合问题。 
    
- 非参数法 Non-parametric methods
    - 非参数法对函数形式没有做出明确的假设
    - 非参数法避免对 $f$ 的特定函数形式的假设，可能精确地确定 $f$ 的更广泛的形式
    - 由于没有对估计的问题简化为少量的参数，因此需要非常多的观测值（远远超过参数法）才能得到 $f$  的准确估计

### 预测精度与模型可解释性之间的权衡

- 如果目的是为了推论（*inference*）限制性的模型会有更多的解释性。而复杂的模型估计很难解释单个自变量与因变量的关联。
- 当我们目标是推断时，使用简单且相对不灵活的统计学习方法有明显的优势

# 评估模型精准度

> 统计中没有免费的午餐：在所有可能的数据集上，没有一种方法可以支配所有其他方法。 在特定的数据集上，一种特定的方法可能效果最好，但另一种方法可能在相似但不同的数据集上效果更好。
> 

### 测定拟合质量

- 在回归设定中，最常用指标的是均方误差（ *mean squared error* ，MSE）
    
    $$
    M S E=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{f}\left(x_{i}\right)\right)^{2}\tag{2.5}
    $$
    
    该指标可用于在训练数据集上拟合模型
    
    在**测试集**上，选择模型时可使用平均平方（*average squared*）
    
    $$
    Ave({y_0}-\hat{f}({x_0}))^2\tag{2.6}
    $$
    
    - 如何选择模型？
        
        有测试集时，选择测试集上**平均平方**和训练集上**均方误差**都小的
        没有测试集时，选择**均方误差**小的
        
    
    在书中图2.9显示，随着模型灵活性的增加，训练的MSE单调下降，测试的MSE程U型。即随着模型灵活性增加，训练MSE会降低，但测试的MSE可能不会。当在某个模型下，训练MSE较小，测试MSE较大时，称之为模型过拟合——过度拟合( *Overfitting* )指的是模型泛化能力低，产生较小的测试$MSE$——即对训练数据中的模式（*pattern*）挖掘过于用力，可能会拾取到一些模式，而这些模式只是由随机机会引起的，而不是由未知函数 $f$ 的真实性质引起的。
    
    ![图 2.9：左：由 $f$ 模拟的数据，用黑色表示。给出了 $f$ 的三个估计：线性回归线(橙色曲线)和两个光滑曲线 ts (蓝色和绿色曲线)。右：训练 $MSE$  (灰色曲线)，测试 $MSE$ (红色曲线)，和所有方法的最小可能测试 $MSE$  (虚线)。正方形表示左手面板中显示的三个 ts 的训练和测试 $MSE$。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled.png)
    
    图 2.9：左：由 $f$ 模拟的数据，用黑色表示。给出了 $f$ 的三个估计：线性回归线(橙色曲线)和两个光滑曲线 ts (蓝色和绿色曲线)。右：训练 $MSE$  (灰色曲线)，测试 $MSE$ (红色曲线)，和所有方法的最小可能测试 $MSE$  (虚线)。正方形表示左手面板中显示的三个 ts 的训练和测试 $MSE$。
    
    无论是否过拟合，我们都期望训练 $MSE$ 小于测试 $MSE$
    

### 偏差-方差权衡

> 方差：使用不同训练数据估计 $\hat{f}$ 时，$\hat f$ 的变化程度。理想情况下，$\hat{f}$  的估计值在不同训练集之间变化不大。而一种方法有较高的方差，那么训练数据集的微小变化就会导致 $\hat{f}$ 的较大变化。越灵活的方法具有越高的方差
偏差：通过一个简单模型来近似一个复杂问题而引入的误差。一般来说，越灵活的方法得到的偏差越小
一般情况下，随着我们使用更灵活的方法，方差会增加，偏差会减小。
> 

对于给定的 $x_0$ ，期望的测试 $MSE$ 总是可以分解为三个基本量的和：$\hat{f}(x_0)$ 的方差，$\hat{f}(x_0)$ 偏差的平方，误差的方差

$$
E\left(y_{0}-\hat{f}\left(x_{0}\right)\right)^{2}=\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)+\left[\operatorname{Bias}\left(\hat{f}\left(x_{0}\right)\right)\right]^{2}+\operatorname{Var}(\epsilon)\tag{2.7}
$$

为了最小化期望的测试误差，需要选择同时实现低方差和低偏差的统计方法。**期望的测试 $MSE$ 不可能低于不可约误差** $Var(\epsilon)$

![图2.12 ：对图 2.9 中的三个数据集进行平方偏差(蓝色曲线)、方差(橙色曲线)、$Var(\epsilon)$ (虚线)和测试$MSE$ (红色曲线)。垂直虚线表示最小测试$MSE$ 对应的灵活度水平。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled%201.png)

图2.12 ：对图 2.9 中的三个数据集进行平方偏差(蓝色曲线)、方差(橙色曲线)、$Var(\epsilon)$ (虚线)和测试$MSE$ (红色曲线)。垂直虚线表示最小测试$MSE$ 对应的灵活度水平。

### 分类情况

定性问题中，例如分类问题，量化 $f$ 准确性的常用方法是**训练错误率**

$$
\frac{1}{n}\sum_{i=1}^{n}I(y_i\neq\hat{y_i})\tag{2.8}
$$

测试错误率：

$$
Ave(I(y_0\neq\hat{y_0}))\tag{2.9}
$$

- 贝叶斯分类
    
    > $\operatorname{Pr}\left(Y=j \mid X=x_{0}\right)$ 已知 $Y$ 的条件分布，给定 $X$ 求出 $Y_i$ 的概率，选择概率最大的为 $X$ 的类
    > 
    
    贝叶斯分类器产生**尽可能低**的测试错误率，称为贝叶斯错误率。 由于贝叶斯分类器将始终选择错误率最大的类，错误率为
    
    $$
    1-E\left(\max _{j} \operatorname{Pr}(Y=j \mid X)\right)\tag{2.11}
    $$
    
    贝叶斯误差率类似于前面讨论的不可约误差
    
    ![图2.13：一个由预测变量$X_1$和 $X_2$ 组成的二维空间中使用模拟数据集的例子。橙色和蓝色圆圈对应于属于两个不同类别的训练观测值。对于 $X_1$ 和 $X_2$ 的每个值，存在不同的响应为橙色或蓝色的概率。由于**这是模拟数据，我们知道数据是如何产生的，我们可以计算 $X_1$ 和 $X_2$ 的每个值的条件概率**。橙色阴影区域表示 $Pr( Y = 橙色| X) >50$% 的点集，蓝色阴影区域表示概率小于50%的点集。紫色虚线表示概率恰好为50%的点，被称为Bayes决策边界。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled%202.png)
    
    图2.13：一个由预测变量$X_1$和 $X_2$ 组成的二维空间中使用模拟数据集的例子。橙色和蓝色圆圈对应于属于两个不同类别的训练观测值。对于 $X_1$ 和 $X_2$ 的每个值，存在不同的响应为橙色或蓝色的概率。由于**这是模拟数据，我们知道数据是如何产生的，我们可以计算 $X_1$ 和 $X_2$ 的每个值的条件概率**。橙色阴影区域表示 $Pr( Y = 橙色| X) >50$% 的点集，蓝色阴影区域表示概率小于50%的点集。紫色虚线表示概率恰好为50%的点，被称为Bayes决策边界。
    

贝叶斯分类预测由贝叶斯决策边界决定；落在边界橙色一侧的观测将被分配到橙色类，同样地，落在边界蓝色一侧的观测将被分配到蓝色类。

- K-近邻

> 但对于真实数据，给定$X$，我们不知道 $Y$ 的条件分布，因此无法计算贝叶斯分类。
> 

$KNN$ 算法：

给定一个正整数 $K$ 和一个观测值 $x_0$ ，$KNN$ 首先从训练数据中确定 $K$ 个最接近 $x_0$ 的点，放入集合  ${N_0}$ ，然后将类别 $j$ 的条件概率估计为 $j$ 的点在 $N_0$ 中的分数：

$$
\Pr(Y=j|X=x_0)=\dfrac1K\sum_{i\in\mathcal N_0}I(y_i=j)\tag{2.12}
$$

$KNN$ 将观测值 $x_0$ 分类到( 2.12 )中概率最大的一类

下图提供了$KNN$方法的示例：

![我们绘制了一个由6个蓝色和6个橙色观测值组成的小型训练数据集。我们的目标是对黑色十字标记的点做出预测。假设我们选择 K=3 ，然后KNN会首先识别最靠近交叉的三个观测值。这个邻域表现为一个圆。由2个蓝色点和1个橙色点组成，蓝色类的估计概率为 2/3，橙色类的估计概率为 1/3。因此KNN会预测黑色十字属于蓝色类。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled%203.png)

我们绘制了一个由6个蓝色和6个橙色观测值组成的小型训练数据集。我们的目标是对黑色十字标记的点做出预测。假设我们选择 K=3 ，然后KNN会首先识别最靠近交叉的三个观测值。这个邻域表现为一个圆。由2个蓝色点和1个橙色点组成，蓝色类的估计概率为 2/3，橙色类的估计概率为 1/3。因此KNN会预测黑色十字属于蓝色类。

尽管KNN是一种非常简单的方法，但它经常可以产生出奇地接近最优贝叶斯分类的类。

![图 2.15：黑色曲线表示 [图 2.13](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a.md) 数据的KNN决策边界，取$K = 10$ 。贝叶斯决策边界如紫色虚线所示。KNN和Bayes决策边界非常相似。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled%204.png)

图 2.15：黑色曲线表示 [图 2.13](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a.md) 数据的KNN决策边界，取$K = 10$ 。贝叶斯决策边界如紫色虚线所示。KNN和Bayes决策边界非常相似。

K 的选择对得到的 $KNN$ 分类器有很大的影响。图2.16给出了K = 1和K = 100时，对图2.13模拟数据的两个KNN 拟合。当K = 1时，决策边界过于灵活，数据中的拟合得到的模式与Bayes决策边界不对应。这对应着一个具有低偏差但极高方差的类。随着K的增加，该方法变得不那么灵活，并产生一个接近线性的决策边界。这对应着一个低方差但高偏差的分类。

![图2.16：在 [图2.13](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a.md) 的数据上比较$K = 1$ 和 $K = 100$得到的 $KNN$ 决策边界(黑色实曲线)。当$K = 1$ 时，决策边界是过度灵活的，而当K = 100时，决策边界不是充分灵活的。贝叶斯决策边界如紫色虚线所示。](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a/Untitled%205.png)

图2.16：在 [图2.13](Statistical%20Learning%20487d300178fa4b8d8c3768f0f6b1c73a.md) 的数据上比较$K = 1$ 和 $K = 100$得到的 $KNN$ 决策边界(黑色实曲线)。当$K = 1$ 时，决策边界是过度灵活的，而当K = 100时，决策边界不是充分灵活的。贝叶斯决策边界如紫色虚线所示。

无论在回归还是分类设定中，选择正确的模型灵活度水平对任何统计学习方法的成功都至关重要。
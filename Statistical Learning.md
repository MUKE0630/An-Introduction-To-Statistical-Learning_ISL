# Statistical Learning

# 什么是统计学习

建立 $X$ 与 $Y$ 的关系，通常可以写为：$Y=f(X)+\epsilon$ 其中 $\epsilon$ 是独立于  $X$ 均值为0的随机误差项。我们通过数据，确定 $f$ 

### 为什么评估 $f$

估计函数 $f$ 可用于预测和推断

- 预测
    
    假设 $\hat{f}$ 和 $X$ 都是确定的，那么唯一的变量来自于 $\epsilon$ 
    
     $\begin{aligned}\mathrm{E}(Y-\hat{Y})^{2} & =\mathrm{E}[f(X)+\epsilon-\hat{f}(X)]^{2} \\& =\underbrace{[f(X)-\hat{f}(X)]^{2}}_{\text {Reducible }}+\underbrace{\operatorname{Var}(\epsilon)}_{\text {Irreducible }}\end{aligned}$
    
    其中 $Var(\epsilon)$ 表示与误差项 $\epsilon$ 相关的方差
    

### 如何估计 $f$

- 参数法 parametric methods
    1. 对 $f$  的形式进行假设（例如假设为线性回归 $f(X)=\beta_{0}+\beta_{1} X_{1}+\beta_{2} X_{2}+\cdots+\beta_{p} X_{p}$ ）
    2. 使用训练数据进行模型拟合
    
    线性回归模型一般使用最小二乘法来拟合，
    
    参数法的潜在缺点是，我们选择的模型与 $f$ 的真实形式不匹配，可以通过选择灵活的模型来解决这个问题，但越复杂越灵活的模型会引起过拟合问题。 
    
- 非参数法 Non-parametric methods
    - 非参数法对函数形式没有做出明确的假设
    - 非参数法避免对 $f$ 的特定函数形式的假设，可能精确地确定 $f$ 的更广泛的形式
    - 由于没有对估计的问题简化为少量的参数，因此需要非常多的观测值（远远超过参数法）才能得到 $f$  的准确估计

### 预测精度与模型可解释性之间的权衡

- 如果目的是为了推论（inference）限制性的模型会有更多的解释性。而复杂的模型估计很难理解单个自变量与因变量的关联。
- 当我们目标是推断时，使用简单且相对不灵活的统计学习方法有明显的优势

# 评估模型精准度

> 统计中没有免费的午餐：在所有可能的数据集上，没有一种方法可以支配所有其他方法。 在特定的数据集上，一种特定的方法可能效果最好，但另一种方法可能在相似但不同的数据集上效果更好。
> 

### 测定拟合质量

- 在回归设定中，最常用指标的是均方误差（ *mean squared error* ，MSE）
    
    $M S E=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{f}\left(x_{i}\right)\right)^{2}$
    
    该指标可用于在训练数据集上拟合模型
    
    在测试集上，选择模型时可使用平均平方（*average squared*）
    
    $Ave({y_0}-\hat{f}({x_0}))^2$
    
    - 如何选择模型？
        
        有测试集时，选择测试集上**平均平方**和训练集上**均方误差**都小的
        没有测试集时，选择**均方误差**小的
        
    
    在书中图2.9显示，随着模型灵活性的增加，训练的MSE单调下降，测试的MSE程U型。即随着模型灵活性增加，训练MSE会降低，但测试的MSE可能不会
    
    当某个模型下，训练MSE较小，测试MSE较大时，称之为模型过拟合，即该模型只是由随即机会引起，而不是未知函数 $f$ 的真实性质引起的
    
    无论是否过拟合，我们都期望训练MSE小于测试MSE
    

### 偏方差权衡

对于给定的 $x_0$ ，期望的测试MSE总是可以分解为三个基本量的和：$\hat{f}(x_0)$ 的方差，$\hat{f}(x_0)$ 偏差的平方，误差的方差

$E\left(y_{0}-\hat{f}\left(x_{0}\right)\right)^{2}=\operatorname{Var}\left(\hat{f}\left(x_{0}\right)\right)+\left[\operatorname{Bias}\left(\hat{f}\left(x_{0}\right)\right)\right]^{2}+\operatorname{Var}(\epsilon)$

为了最小化期望的测试误差，需要选择同时实现低方差和低偏差的统计方法。期望的测试MSE不可能低于不可约误差 $Var(\epsilon)$

> 方差：使用不同训练数据估计 $\hat{f}$ ，$\hat{f}$ 的该变量，理想情况下，$\hat{f}$  的估计值在不同训练集之间变化不大。而一种方法由较高的方差，那么训练数据集的微小变化就会导致 $\hat{f}$ 的较大变化。越灵活的方法具有更高的方差
偏差：通过一个简单模型来近似一个复杂问题而引入的误差。一般来说
> 

### 分类情况

定性问题中，例如分类问题，量化 $f$ 准确性的常用方法是**训练错误率**

$\frac{1}{n}\sum_{i=1}^{n}I(y_i\neq\hat{y_i})$

测试错误率：$Ave(I(y_0\neq\hat{y_0}))$be

- 贝叶斯分类
    
    > $\operatorname{Pr}\left(Y=j \mid X=x_{0}\right)$ 已知 Y 的条件分布，给定 $X$ 求出 $Y_i$ 的概率，选择概率最大的为 $X$ 的类
    > 
    
    贝叶斯分类器产生尽可能低的测试错误率，称为贝叶斯错误率。 由于贝叶斯分类器将始终选择 错误率最大的类，错误率为
    
    $1-E\left(\max _{j} \operatorname{Pr}(Y=j \mid X)\right)$
    
    贝叶斯误差率类似于前面讨论的不可约误差
    
    许多方法试图在给定 $X$ 的情况下估计 $Y$ 的条件分布，然后将给定的观测分类到估计概率最高的类。其中一种方法是K近邻( KNN )分类。